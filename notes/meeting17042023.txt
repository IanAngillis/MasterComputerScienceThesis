What did I do: 
    * Show detection rules
    * Explain predicament with more precise detection
    * Show results
    * Ask about dataset
    * Discuss doubts first session

What answers did I get:
    * Make sure you explain that your tool is more precise, but it seems fine to consolidate that information  when there is overlap. Check why one tool is able to detect more (or less) than another.
    * Read paper of Security Smells to get an idea of how to do the verification
        * It is fine to take a lot of inspiration from it
    * For the dataset - it is fine to take an existing one
        * Also try to run it on samples of StackOverflows
        * Manuel verification on a predetermined sample size. Compare more tools
    * You don't need to repair all the smells, do the easy ones first
    * Detect the low-churn smell
    * Extra: fix up the catalogue.
    * You can do it first session, check with Coen for second session
        * Writing background takes the most work
        * Writing evaluation takes is pretty intuitive.


27042023
    * Find the alternatives for the json files
    * Write script to run entire pipeline and string different pieces of code together
    * Define the low-churn smell --> DONE
    * Do the dataset of camilo and run overnight
    * Look into repairing
    * Read the paper from Ahmed to check verification
    * Repair the low churn smell  
        * Pip install dependencies before copying the rest of the context?
        * Whenever something needs installing dependencies from something that is copied over?
        * If you are going to install from specifics and you copy entire context before - put the copying of context later
        * Careful for multi-stagebuilds when swapping around instructions. Something not to worry about when changing text in a run instruction
        * 6a797aa18de54498c54a5eb094bdd404c05e1818 bourbon install after copying entire context
        * yarn install?

https://www.youtube.com/watch?v=BYQQlCVt4aE&ab_channel=CassieKozyrkov
    FIX: 

FROM node:latest

# Create app directory
WORKDIR /usr/src/app

# Install app dependencies
COPY package.json package-lock.json ./

RUN npm install

# Bundle app source
COPY . .

CMD ["node","index.js"]


Detection:
* Fix-list -- if that doesn't work we go fixpoint.
* Maybe not a fixlist but 2 passes are required.
    * Pass over all the smells that need removal of files -- then fix -- then repeat with ones that only add.
        Could have problems as the repair isn't that neat... preferably everything in one pass. Then again, if layers are the problem those should be able to get updated.
        Actually, every time we add a statement we can derive the layer from the surrounding nodes.
        Actually, every time we add a dockerstatement, we can assign new layers, these should update in the fixlist.
        This way - replaces can be done without harm. And deleted ones can be deleted from the fixlist.
* I require the building context in order to build the images ... 